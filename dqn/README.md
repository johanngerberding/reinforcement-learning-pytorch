# Deep Q-Networks

This repository contains my implementation of the classic [DQN Network](https://arxiv.org/abs/1312.5602). You can also use **n-step** option to speed up training and [Double DQNs](https://arxiv.org/abs/1509.06461) to reduce value overestimation.

# TODOs

* Noisy Networks 
* Prioritized Experience Replay
* Dueling DQN
* Categorical DQN
* Test with other atari envs than pong and make sure they all work
* script to run experiments (create script to run this with different hyperparameters (in parallel?))

# References

* [DQN](https://arxiv.org/abs/1312.5602)
* [Double DQN](https://arxiv.org/abs/1509.06461)
* [Noisy Networks](https://arxiv.org/abs/1706.10295)
* [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952)
* [Dueling DQN](https://arxiv.org/abs/1511.06581)
* [Categorical DQN](https://arxiv.org/abs/1707.06887)